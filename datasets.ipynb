{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee824439-fd6e-480e-9fe7-2cc9710b2566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n德语->英语翻译数据集\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "德语->英语翻译数据集\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "778de501-f75b-47b8-9e20-0eed49bf635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "from typing import Iterable, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be6b04cb-80a4-496f-ba80-ef559ee2e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")\n",
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def de_tokenizer(text):\n",
    "    return [tok.text.lower() for tok in de_nlp(text)]\n",
    "\n",
    "def en_tokenizer(text):\n",
    "    return [tok.text.lower() for tok in en_nlp(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "718de846-d01c-4f2e-960e-63629d8ce73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi30kDataset(Dataset):\n",
    "    def __init__(self, de_path: str, en_path: str):\n",
    "        with open(de_path, encoding=\"utf-8\") as f:\n",
    "            self.de_lines = f.readlines()\n",
    "        with open(en_path, encoding=\"utf-8\") as f:\n",
    "            self.en_lines = f.readlines()\n",
    "\n",
    "        assert len(self.de_lines) == len(self.en_lines)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.de_lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.de_lines[idx].strip(), self.en_lines[idx].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eea869e6-f69e-437a-928d-95ba28a9cb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, counter, specials):\n",
    "        self.itos = list(specials)\n",
    "        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n",
    "\n",
    "        for token, freq in counter.items():\n",
    "            if token not in self.stoi:\n",
    "                self.stoi[token] = len(self.itos)\n",
    "                self.itos.append(token)\n",
    "\n",
    "        self.default_index = None\n",
    "\n",
    "    def set_default_index(self, idx):\n",
    "        self.default_index = idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def __call__(self, tokens: List[str]):\n",
    "        return [\n",
    "            self.stoi.get(tok, self.default_index)\n",
    "            for tok in tokens\n",
    "        ]\n",
    "\n",
    "\n",
    "def build_vocab_from_iterator_compat(\n",
    "    iterator: Iterable[List[str]],\n",
    "    specials: List[str],\n",
    "    special_first: bool = True,\n",
    "):\n",
    "    counter = Counter()\n",
    "    for tokens in iterator:\n",
    "        counter.update(tokens)\n",
    "\n",
    "    return Vocab(counter, specials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb602031-cc6b-4517-b13a-bbe696389968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 特殊 token ======\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "UNK_SYM, PAD_SYM, BOS_SYM, EOS_SYM = \"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"\n",
    "# ====== dataset ======\n",
    "DATA_DIR = \"./multi30k\"\n",
    "train_dataset = Multi30kDataset(\n",
    "    f\"{DATA_DIR}/train.1.de\",\n",
    "    f\"{DATA_DIR}/train.1.en\",\n",
    ")\n",
    "\n",
    "# ====== 构建 token 序列 ======\n",
    "de_tokens = []\n",
    "en_tokens = []\n",
    "\n",
    "for de, en in train_dataset:\n",
    "    de_tokens.append(de_tokenizer(de))\n",
    "    en_tokens.append(en_tokenizer(en))\n",
    "\n",
    "# ====== vocab（接口与原来一致） ======\n",
    "de_vocab = build_vocab_from_iterator_compat(\n",
    "    de_tokens,\n",
    "    specials=[UNK_SYM, PAD_SYM, BOS_SYM, EOS_SYM],\n",
    "    special_first=True,\n",
    ")\n",
    "de_vocab.set_default_index(UNK_IDX)\n",
    "\n",
    "en_vocab = build_vocab_from_iterator_compat(\n",
    "    en_tokens,\n",
    "    specials=[UNK_SYM, PAD_SYM, BOS_SYM, EOS_SYM],\n",
    "    special_first=True,\n",
    ")\n",
    "en_vocab.set_default_index(UNK_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ec3a4e2-e606-40ce-9d13-919f601354b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_preprocess(de_sentence):\n",
    "    tokens = de_tokenizer(de_sentence)\n",
    "    tokens = [BOS_SYM] + tokens + [EOS_SYM]\n",
    "    ids = de_vocab(tokens)\n",
    "    return tokens, ids\n",
    "\n",
    "\n",
    "def en_preprocess(en_sentence):\n",
    "    tokens = en_tokenizer(en_sentence)\n",
    "    tokens = [BOS_SYM] + tokens + [EOS_SYM]\n",
    "    ids = en_vocab(tokens)\n",
    "    return tokens, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddb12d5a-ee24-4aac-9622-ec868b305a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de vocab: 13444\n",
      "en vocab: 11982\n",
      "de preprocess: ['<bos>', 'zwei', 'männer', 'betrachten', 'etwas', 'im', 'garten', '<eos>'] [2, 4, 5, 6, 7, 8, 9, 3]\n",
      "en preprocess: ['<bos>', 'two', 'young', 'guys', 'with', 'shaggy', 'hair', 'look', 'at', 'their', 'hands', 'while', 'hanging', 'out', 'in', 'the', 'yard', '.', '<eos>'] [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 3]\n"
     ]
    }
   ],
   "source": [
    "print(\"de vocab:\", len(de_vocab))\n",
    "print(\"en vocab:\", len(en_vocab))\n",
    "\n",
    "de_sentence, en_sentence = train_dataset[0]\n",
    "print(\"de preprocess:\", *de_preprocess(de_sentence))\n",
    "print(\"en preprocess:\", *en_preprocess(en_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046614b-1456-4307-8d97-4ddb51db9277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
