{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b3e8db-00f2-48df-a56d-6793fbdc735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "encoder block支持堆叠, 每个block都输入emb序列并输出emb序列(1:1对应)\n",
    "'''\n",
    "from torch import nn \n",
    "import torch \n",
    "from multihead_attn import MultiHeadAttention\n",
    "from emb import EmbeddingWithPosition\n",
    "from dataset import de_preprocess,train_dataset,de_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "673bf4a8-eb58-4a8b-a6c3-3e7afeaef957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,emb_size,q_k_size,v_size,f_size,head):\n",
    "        super().__init__()\n",
    "\n",
    "        self.multihead_attn=MultiHeadAttention(emb_size,q_k_size,v_size,head)   # 多头注意力矩阵 \n",
    "        self.z_linear=nn.Linear(head*v_size,emb_size) # 调整多头输出尺寸为emb_size，即让head * v_size == emb_size\n",
    "        self.addnorm1=nn.LayerNorm(emb_size) # 按last dim做norm即对emb_size做一次归一化\n",
    "\n",
    "         # feed-forward结构\n",
    "        self.feedforward=nn.Sequential(\n",
    "            nn.Linear(emb_size,f_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(f_size,emb_size)\n",
    "        )\n",
    "        \n",
    "        self.addnorm2=nn.LayerNorm(emb_size)  # 按last dim做norm即对emb_size再做一次归一化\n",
    "\n",
    "    def forward(self,x,attn_mask): # x: (batch_size,seq_len,emb_size)\n",
    "        #多头注意力\n",
    "        z=self.multihead_attn(x,x,attn_mask)  # z: (batch_size,seq_len,head*v_size) \n",
    "        z=self.z_linear(z) # z: (batch_size,seq_len,emb_size)\n",
    "        output1=self.addnorm1(z+x) # z: (batch_size,seq_len,emb_size) 这里就是残差链接并做归一化\n",
    "        #前向反馈\n",
    "        z=self.feedforward(output1) # z: (batch_size,seq_len,emb_size) \n",
    "        return self.addnorm2(z+output1) # (batch_size,seq_len,emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f62b49-dd24-48f3-9267-78bab0ad8553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_result: torch.Size([1, 8, 128])\n",
      "encoder_outputs: torch.Size([1, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    # 准备1个batch\n",
    "    emb=EmbeddingWithPosition(len(de_vocab),128)\n",
    "    de_tokens,de_ids=de_preprocess(train_dataset[0][0]) # 取de句子转词ID序列\n",
    "    de_ids_tensor=torch.tensor(de_ids,dtype=torch.long)\n",
    "    emb_result=emb(de_ids_tensor.unsqueeze(0)) # 转batch再输入模型\n",
    "    print('emb_result:', emb_result.size())\n",
    "\n",
    "    attn_mask=torch.zeros((1,de_ids_tensor.size()[0],de_ids_tensor.size()[0])) # batch中每个样本对应1个注意力矩阵\n",
    "\n",
    "    # 5个Encoder block堆叠\n",
    "    encoder_blocks=[]\n",
    "    for i in range(5):\n",
    "        encoder_blocks.append(EncoderBlock(emb_size=128,q_k_size=256,v_size=512,f_size=512,head=8))\n",
    "    \n",
    "    # 前向forward\n",
    "    encoder_outputs=emb_result\n",
    "    for i in range(5):\n",
    "        encoder_outputs=encoder_blocks[i](encoder_outputs,attn_mask)\n",
    "    print('encoder_outputs:',encoder_outputs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ba706-f38e-4b0a-beb6-08c40dc01371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
